import os
import subprocess
import pandas as pd

# Загрузка данных из HDFS
print("Загрузка данных из HDFS...")

# Путь к данным в HDFS (правильный путь)
hdfs_path = "/user/hadoop/input/myfile.csv"
local_path = "/opt/myfile.csv"

# Скачиваем файл из HDFS
try:
    # Команда для скачивания из HDFS
    hdfs_download_cmd = f"hdfs dfs -get {hdfs_path} {local_path}"
    print(f"Выполнение команды: {hdfs_download_cmd}")
    
    # Задаем JAVA_HOME, так как Jupyter может его не видеть
    env = dict(os.environ, **{'JAVA_HOME': '/usr/lib/jvm/java-11-openjdk-amd64'})
    result = subprocess.run(hdfs_download_cmd, shell=True, capture_output=True, text=True, cwd="/opt", env=env)
    
    if result.returncode == 0:
        print(f"Данные успешно загружены из HDFS: {hdfs_path}")
    else:
        print(f"Ошибка при загрузке из HDFS: {result.stderr}")
        print("Попытка найти файл локально...")
        local_path = "/opt/data/myfile.csv"
        
    # Проверяем наличие файла
    if not os.path.exists(local_path):
        print(f"Файл не найден в {local_path}. Используем альтернативный путь...")
        local_path = "myfile.csv"
        
except Exception as e:
    print(f"Ошибка при выполнении subprocess: {e}")
    print("Попытка использовать локальный файл...")
    local_path = "/opt/data/myfile.csv"

# Проверяем наличие файла перед загрузкой
if not os.path.exists(local_path):
    print("Файл не найден. Пробуем последний вариант...")
    local_path = "myfile.csv"

# Финальная проверка и загрузка данных
if os.path.exists(local_path):
    df = pd.read_csv(local_path, low_memory=False)
    print(f"Размер датасета: {df.shape}")
    print(f"Данные успешно загружены из {local_path}")
    print(df.head())
else:
    print(f"ОШИБКА: Файл myfile.csv не найден!")
    print(f"Искали по следующим путям:")
    print(f"  - /opt/myfile.csv (из HDFS)")
    print(f"  - /opt/data/myfile.csv (локальный)")
    print(f"  - myfile.csv (в текущей директории)")
    df = pd.DataFrame()  # Создаем пустой DataFrame чтобы не было ошибки
